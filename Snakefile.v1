import os
import sys
from snakemake.io import glob_wildcards
import yaml
import csv
import itertools
import pandas as pd
from scripts.parser import *
from datetime import datetime




configfile : parser(config["file"])
comparisonGroupTuples, cgSpecieDict, cgCounter,specieGenomeSizeDict, cgSampleDict = setComparisonGroups(config)
print(cgSampleDict)
output_dir = "output"
krakenDB = "/workspace/WGS-pipeline/databases/k2"
print(specieGenomeSizeDict)


# Define the final rule that specifies the targets to generate
rule all:
    input:  
        expand(output_dir+"/fastq/{sample}/{sample}.clean_fwd.fastq.gz", sample = config["Samples"].keys()),
        expand(output_dir+"/fastq/{sample}/{sample}.clean_rev.fastq.gz", sample = config["Samples"].keys()),
        expand(output_dir+"/readSpeciesID/kraken/{sample}/{sample}.kraken_taxonomy.txt", sample = config["Samples"].keys()),
        expand(output_dir+"/readSpeciesID/kraken/{sample}/{sample}.kraken_output.txt", sample = config["Samples"].keys()),
        expand(output_dir+"/readSpeciesID/bracken/{sample}.bracken_output.tsv", sample = config["Samples"].keys()),
        expand(output_dir+"/readSpeciesID/sample_validation/{sample}.output.txt", sample = config["Samples"].keys()),
        expand(output_dir+"/assembly/comparisonGroup{comparisonGroup}/{sample}_assembly/contigs.fa", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/assemblySpeciesID/wgkb/comparisonGroup{comparisonGroup}/{sample}/{sample}.kraken_taxonomy.txt", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/assemblySpeciesID/wgkb/comparisonGroup{comparisonGroup}/{sample}/{sample}.kraken_output.txt", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/assemblySpeciesID/wgkb/comparisonGroup{comparisonGroup}/{sample}/{sample}.bracken_output.txt", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/assemblySpeciesID/wgv/{sample}/{sample}.validation_output.txt", sample = config["Samples"].keys()),
        expand(output_dir+"/assemblySpeciesID/mlst/comparisonGroup{comparisonGroup}/{sample}.contigs.mlst.tsv", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/assemblySpeciesID/rmlst/comparisonGroup{comparisonGroup}/{sample}.tsv", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/abricate/comparisonGroup{comparisonGroup}/card/{sample}.abricate.card.tsv", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/abricate/comparisonGroup{comparisonGroup}/vfdb/{sample}.abricate.vfdb.tsv", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/AMR/comparisonGroup{comparisonGroup}/{sample}.amrfinderplus.tsv", zip, comparisonGroup = [item[0] for item in comparisonGroupTuples], sample = [item[1] for item in comparisonGroupTuples]),
        expand(output_dir+"/cgMLST/comparisonGroup{comparisonGroup}/contigs_dir", comparisonGroup = [item[0] for item in comparisonGroupTuples]),
        expand(output_dir+"/cgMLST/trainingFiles/comparisonGroup{comparisonGroup}.trn",comparisonGroup = [item[0] for item in comparisonGroupTuples]),
        expand(output_dir+"/cgMLST/comparisonGroup{comparisonGroup}/schema", comparisonGroup = [item[0] for item in comparisonGroupTuples]),
        expand(output_dir+"/cgMLST/comparisonGroup{comparisonGroup}/Allelecall",  comparisonGroup = [item[0] for item in comparisonGroupTuples]),
        expand(output_dir+"/cgMLST/comparisonGroup{comparisonGroup}/MST", comparisonGroup = [item[0] for item in comparisonGroupTuples]),
        expand(output_dir+"/cgMLST/comparisonGroup{comparisonGroup}/grapetree/cgMLST100.tre", comparisonGroup = [item[0] for item in comparisonGroupTuples])
        
        
rule process_file_pair:
    conda:
        "env/conda-qc.yaml"
    threads:
        3
    priority:
        50
    input:
        fwd = lambda wildcards: config["Samples"][wildcards.id[:7]]["R1Fastq"],
        rev = lambda wildcards: config["Samples"][wildcards.id[:7]]["R2Fastq"]
    output:
        r1_clean = os.path.join(output_dir, "fastq/{id}/{id}.clean_fwd.fastq.gz"),
        r2_clean = os.path.join(output_dir, "fastq/{id}/{id}.clean_rev.fastq.gz"),
        html = temporary(os.path.join(output_dir, "fastq/{id}/{id}.fastp.html")),
        json = temporary(os.path.join(output_dir, "fastq/{id}/{id}.fastp.json"))
    log:
        output_dir+"/fastq/{id}/{id}.fastp.log.txt"
    shell:
        """
        fastp -i {input.fwd} -I {input.rev} \
              --out1 {output.r1_clean} --out2 {output.r2_clean} \
              -w 3 -h {output.html} -j {output.json}
        """

rule run_kraken2:
    conda:
        "env/conda-kraken_and_bracken.yaml"
    params:
        db = krakenDB
    input:
        clean_fwd=lambda wildcards: os.path.join(output_dir, "fastq", wildcards.id, f"{wildcards.id}.clean_fwd.fastq.gz"),
        clean_rev=lambda wildcards: os.path.join(output_dir, "fastq", wildcards.id, f"{wildcards.id}.clean_rev.fastq.gz")
    priority:
        25
    output:
        kraken_report = os.path.join(output_dir,"readSpeciesID","kraken", "{id}", "{id}.kraken_taxonomy.txt"),
        kraken_output = os.path.join(output_dir,"readSpeciesID","kraken", "{id}", "{id}.kraken_output.txt"),
    threads: 
         4
    shell:
        """
        kraken2 --db {params.db} --threads 4 --report {output.kraken_report} --output {output.kraken_output}\
        --paired {input.clean_fwd} {input.clean_rev}
        """

rule run_bracken:
    conda:
        "env/conda-kraken_and_bracken.yaml"
    params:
        db = krakenDB
    input:
       kraken_report_file= lambda wildcards: os.path.join(output_dir,"readSpeciesID", "kraken", wildcards.id, f"{wildcards.id}.kraken_taxonomy.txt")
    output:
        bracken_output= os.path.join(output_dir,"readSpeciesID", "bracken", "{id}.bracken_output.tsv")
    shell:
        """
            bracken -i {input.kraken_report_file} -d {params.db} -o {output.bracken_output}
            
        """

        
rule sample_validation:
    input: 
        bracken_output_file = lambda wildcards: os.path.join(output_dir,"readSpeciesID", "bracken", f"{wildcards.id}.bracken_output.tsv"),
    output:
        sample_validation_output = os.path.join(output_dir, "readSpeciesID", "sample_validation", "{id}.output.txt")
    params:
        specie = lambda wildcards: config["Samples"][wildcards.id[:7]]["specie"],
        sample_id = lambda wildcards: wildcards.id
    shell:    
         """
         python scripts/samp_val.py --input {input.bracken_output_file} --output {output.sample_validation_output} {params.specie} {params.sample_id}
         
         """

rule assembly:
    conda:
         "env/conda-assembly.yaml"
    priority:
        50
    threads: 
        8
    input:
        clean_fwd = os.path.join(output_dir, "fastq", "{id}", "{id}.clean_fwd.fastq.gz"),
        clean_rev = os.path.join(output_dir, "fastq", "{id}", "{id}.clean_rev.fastq.gz"),
    params:
        genome_size = lambda wildcards: specieGenomeSizeDict[config["Samples"][wildcards.id[:7]]["specie"]]
    output:
        assembly_dir = directory(os.path.join(output_dir, "assembly", "{comparisonGroup}", "{id}_assembly")),
        assembly_output = os.path.join(output_dir, "assembly", "{comparisonGroup}", "{id}_assembly","contigs.fa")
    shell:
        """
        shovill --cpus {threads} --R1 {input.clean_fwd} --R2 {input.clean_rev} --force --gsize {params.genome_size}M --outdir {output.assembly_dir} --assembler skesa
        
        """

rule whole_genome_krak_brack:
    conda:
        "env/conda-kraken_and_bracken.yaml"
    params:
        specie = lambda wildcards: config["Samples"][wildcards.id[:7]]["specie"],
        sample_id = lambda wildcards: wildcards.id,
        db = krakenDB
    input:
        contigs_file = os.path.join(output_dir, "assembly","{comparisonGroup}","{id}_assembly","contigs.fa")
    output:
        wgv_kraken_report = os.path.join(output_dir, "assemblySpeciesID","wgkb","{comparisonGroup}" ,"{id}", "{id}.kraken_taxonomy.txt"),
        wgv_kraken_output = os.path.join(output_dir, "assemblySpeciesID","wgkb","{comparisonGroup}", "{id}", "{id}.kraken_output.txt"),
        wgv_bracken_output = os.path.join(output_dir, "assemblySpeciesID","wgkb", "{comparisonGroup}","{id}", "{id}.bracken_output.txt"),
    shell:
        """
        kraken2 --db {params.db} \
         --threads 4 --report {output.wgv_kraken_report} --output {output.wgv_kraken_output} {input.contigs_file}

        bracken -i {output.wgv_kraken_report} -d {params.db}\
         -o {output.wgv_bracken_output}

        """
rule whole_genome_validation:
    input:
        bracken_output =  os.path.join(output_dir, "assemblySpeciesID","wgkb","{id}", "{id}.bracken_output.txt"),
    params:
        specie = lambda wildcards: config["Samples"][wildcards.id[:7]]["specie"],
        sample_id = lambda wildcards: wildcards.id
    output:
        wgv_sample_validation_output = os.path.join(output_dir ,"assemblySpeciesID" ,"wgv" ,"{id}.validation_output.txt")
    shell:
        """
        python scripts/samp_val.py --input {input.bracken_output} --output {output.wgv_sample_validation_output} {params.specie} {params.sample_id}  
        """
rule run_mlst:
    conda:
        "env/conda-mlst.yaml"
    params:
        comparisonGroup = lambda wildcards: config["Samples"][wildcards.id[:7]]["comparisonGroup"]
    input:
        contigs_file = os.path.join(output_dir, "assembly","{comparisonGroup}", "{id}_assembly","contigs.fa")
    output:
        mlst_output = os.path.join(output_dir,"assemblySpeciesID" ,"mlst","{comparisonGroup}", "{id}.contigs.mlst.tsv"),
        rmlst_output = os.path.join(output_dir,"assemblySpeciesID", "rmlst", "{comparisonGroup}","{id}.tsv")
    shell:
        """
        mlst {input.contigs_file} > {output.mlst_output}
        bash ./rMLST/rmlst.sh {input.contigs_file} > {output.rmlst_output}
        
        """
rule resistome_and_virulome:
    conda:
        "env/conda-resistome_and_virulome.yaml"
    params:
        comparisonGroup = lambda wildcards: config["Samples"][wildcards.id[:7]]["comparisonGroup"]
    input:
        contigs_file = os.path.join(output_dir, "assembly","{comparisonGroup}","{id}_assembly","contigs.fa"),
    output:
        abricate_card = os.path.join(output_dir,"abricate","{comparisonGroup}","card","{id}.abricate.card.tsv"),
        abricate_vfdb = os.path.join(output_dir,"abricate","{comparisonGroup}","vfdb","{id}.abricate.vfdb.tsv"),
        AMR = os.path.join(output_dir,"AMR","{comparisonGroup}","{id}.amrfinderplus.tsv")
    shell:
        """
        abricate --db card --minid 60 --mincov 60 {input.contigs_file} > {output.abricate_card}
        abricate --db vfdb --minid 60 --mincov 60 {input.contigs_file} > {output.abricate_vfdb}
        amrfinder -u
        amrfinder --nucleotide {input.contigs_file} --plus --threads 4 -o {output.AMR}
        """

rule create_contig_dirs:
    input:
        assembly = lambda wildcards: expand(os.path.join(output_dir, "assembly", f"{wildcards.comparisonGroup}", "{sample}_assembly", "contigs.fa"), sample=cgSampleDict[f"{wildcards.comparisonGroup}"[-1]]),
    output:
        contigs_dir = directory(os.path.join(output_dir,"cgMLST","{comparisonGroup}","contigs_dir"))
    shell:
        """
        python scripts/extract_contigs.py {input.assembly[0]} {output.contigs_dir} 
        """



rule create_training_file:
    conda:
        "env/conda-prodigal.yaml"
    params:
        specie = lambda wildcards: cgSpecieDict[wildcards.comparisonGroup[-1]],
        specie_no_spaces=lambda wildcards: cgSpecieDict[wildcards.comparisonGroup[-1]].replace(" ","") 
    output:
       training_file = os.path.join(output_dir,"cgMLST","trainingFiles","{comparisonGroup}.trn")
    shell:
        """
        datasets download genome taxon "{params.specie}" --assembly-level complete --reference --include genome --filename {params.specie_no_spaces}_ref.zip
        prodigal -i {params.specie}_ref.zip -t {output.training_file} -p single

        """    


rule adhoc_cgMLST:
    conda:
        "env/conda-chewBBACA.yaml"
    params:
        comparisonGroup = lambda wildcards: wildcards.comparisonGroup
    input:
        contigs_dir = os.path.join(output_dir,"cgMLST","{comparisonGroup}","contigs_dir"),
        training_file = os.path.join(output_dir,"cgMLST","trainingFiles","{comparisonGroup}.trn"),
    output:
        createSchema = directory(os.path.join(output_dir,"cgMLST","{comparisonGroup}","schema")),
        allelecall = directory(os.path.join(output_dir,"cgMLST","{comparisonGroup}","Allelecall")),
        MST = directory(os.path.join(output_dir,"cgMLST","{comparisonGroup}","MST"))

    shell:
      """

        chewBBACA.py CreateSchema -i {input.contigs_dir} -o {output.createSchema} --ptf {input.training_file} --cpu 20

        # Loop until the condition is met
        until chewBBACA.py AlleleCall -i {input.contigs_dir} -g {output.createSchema}/schema_seed/ -o {output.allelecall} --cpu 14; do
            if [ ! -f {output.allelecall}/results_statistics.tsv ]; then
                continue
            fi

            if python -c "import sys, os; sys.exit(0 if os.path.exists('{output.allelecall}/results_statistics.tsv') and all(line.split('\\t')[1].strip() == '0' for line in open('{output.allelecall}/results_statistics.tsv')) else 1)"; then
                break
            fi
        done

        cut -f 2 {output.allelecall}/paralogous_loci.tsv | sed 's/|/\\n/g' {output.allelecall}/paralogous_loci.tsv
        chewBBACA.py RemoveGenes -i {output.allelecall}/results_alleles.tsv -g {output.allelecall}/paralogous_loci.tsv -o {output.allelecall}/results_alleles.no_paralogs.tsv
        chewBBACA.py ExtractCgMLST -i {output.allelecall}/results_alleles.no_paralogs.tsv -o {output.MST}
        """

rule grapetree:
    conda:
        "env/conda-grapetree.yaml"
    input:
        grapetree_input = os.path.join(output_dir,"cgMLST","{comparisonGroup}","MST")
    output:
        grapetree_output = os.path.join(output_dir,"cgMLST","{comparisonGroup}","grapetree","cgMLST100.tre")
    shell:
        """
        grapetree --profile {input.grapetree_input}/cgMLST100.tsv > {output.grapetree_output}

        """

    